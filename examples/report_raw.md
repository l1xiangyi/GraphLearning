for my optimization final paper, please help me find typo and broken english. do not count mathmatical symbols as typo

# Introduction

Clustering has been an established unsupervised learning method to group similar data with no requirement on labeling the training data. In most scienctific fields that require dealing with empirical data, clustering is one of the most used exploratory data analysis techniques. Since [1] K-means clustering has been widely used. K-means algorithm clusters data by trying to separate samples in n groups of equal variance, minimizing a criterion known as the inertia or within-cluster sum-of-square. However, [2] has shown traditional clustering algorithms have some fundamental limitations such as inability of not clustering non-convex and high-dimensional data well. Thee spectral clustering algorithm, especially the one proposed by [3] is not only easy to implement but also outperforms K-means and other clustering algorithm shown by a comparison of different clustering algorithms from [4]. The spectral clustering algorithm considers good clusters as graphs that maximizes in-cluster edges and minimize inter-cluster cuts. It applies clustering to a projection of the normalized Laplacian. Below is a visualization on a toy dataset: 

# Spectral Clustering

Given a dataset ğ‘‹ = {ğ‘¥1 , ..., ğ‘¥ğ‘› }, assume the similarity between ğ‘¥ğ‘– and ğ‘¥ğ‘— is ğ‘ ğ‘–ğ‘— â‰¥ 0. The idea of spec- tral clustering is to divide the data points into different clusters so that the points within the same cluster are similar, while the points in different clusters are dissimilar to each other. Here we use sim- ilarity graph ğº = (ğ‘‰ , ğ¸) to represent the dataset.

## Graph Cut 
Let ğº = (ğ‘‰ , ğ¸) be the similarity graph, where ğ‘‰ = {ğ‘£1, ..., ğ‘£ğ‘›} and each vertex ğ‘£ğ‘– denotes a data point. We assume the graph is weighted and each edge between ğ‘£ğ‘– and ğ‘£ğ‘— carries a non-negative weight ğ‘¤ğ‘–ğ‘—. î‰en the weighted adjacency matrix is constructed as

The degree matrix of G is defined as:

To cluster the graph into several clusters, we want to minimize the weight of edges between different clusters. In a k-cluster problem, the minicut approach is to choose a partition ğ´1 , ..., ğ´ğ‘˜ which mini- mizes

and the optimization problem can be written as

Although mincut is a relatively easy problem to solve, it oî€¹en does not lead to satisfactory partitions, for the reason that in many cases, it simply seperates one individual vertex from the rest of the graph. To solve this problem, we want to constrain the size of the clusters so that they are â€œreasonably largeâ€. Normalized cut (Ncut) is one of the most common objective functions used to solve the problem.

## Normalized cut for k-cluster problem
Normalized cut (Ncut) provides balanced graph partition by constraining the size of the clusters to be similar. Let vol(ğ´ğ‘–) = âˆ‘ğ‘–âˆˆğ´ ğ‘‘ğ‘– denotes the size of edges in cluster ğ´ğ‘–. Normalized cut for k clusters is defined as:

where ğ´ stands for the complement of cluster ğ´ğ‘–

Then the optimization problem constructed by normalized cut is

î‰e minimum of âˆ‘ğ‘˜ ô°… 1 ô°† is achieved if all vol(ğ´ğ‘–) coincide. However, solving this problem is NP ğ‘–=1 vol(ğ´)
hard. î‰us we use spectral clustering to solve the relaxed version of the problem.
î‰e objective function can be rewriî€¼en using graph Laplacian. Define the cluster inidcator vector hğ‘— = ô°‡h1,ğ‘—,...,hğ‘›,ğ‘—ô°ˆğ‘‡ as